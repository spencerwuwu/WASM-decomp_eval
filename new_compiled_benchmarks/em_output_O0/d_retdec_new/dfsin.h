int64_t __asm_movsd(int64_t, ...);
int64_t __asm_movsd_1(int64_t, ...);
int64_t __asm_subsd(int64_t, ...);
int64_t __asm_cvtsi2sd(int64_t, ...);
int64_t __asm_cvtsi2sd_2(int64_t, ...);
int64_t __asm_addsd(int64_t, ...);
int64_t __asm_mulsd(int64_t, ...);
int64_t shift64RightJamming(uint64_t a1, int64_t a2, int64_t result) ;
void shift64ExtraRightJamming(uint64_t a0, int64_t a1, int32_t count, int64_t * z0Ptr, int64_t * z1Ptr) ;
void add128(int64_t a0, uint64_t a1, int64_t b0, int64_t b1, int64_t * z0Ptr, int64_t * z1Ptr) ;
void sub128(int64_t a0, uint64_t a1, int64_t b0, uint64_t b1, int64_t * z0Ptr, int64_t * z1Ptr) ;
void mul64To128(uint64_t a, uint64_t b, int64_t * z0Ptr, int64_t * z1Ptr) ;
void float_raise(int32_t flags) ;
int32_t float64_is_nan(int64_t a) ;
int32_t float64_is_signaling_nan(int64_t a) ;
int64_t extractFloat64Frac(int64_t a) ;
int32_t extractFloat64Exp(uint64_t a) ;
int32_t extractFloat64Sign(uint64_t a) ;
void normalizeFloat64Subnormal(int64_t aSig, int32_t * zExpPtr, int64_t * zSigPtr) ;
int32_t countLeadingZeros64(uint64_t a) ;
int32_t countLeadingZeros32(uint32_t a) ;
int64_t packFloat64(uint32_t zSign, uint32_t zExp, int64_t zSig) ;
int64_t roundAndPackFloat64(int32_t zSign, int32_t zExp, int64_t zSig) ;
int64_t normalizeRoundAndPackFloat64(int32_t zSign, int32_t zExp, int64_t zSig) ;
int64_t int32_to_float64(int32_t a) ;
int64_t addFloat64Sigs(int64_t a, int64_t b, int32_t zSign) ;
int64_t propagateFloat64NaN(int64_t a, int64_t b) ;
int64_t subFloat64Sigs(int64_t a, int64_t b, int32_t zSign) ;
int64_t float64_add(int64_t a, int64_t b) ;
int64_t float64_mul(int64_t a, int64_t b) ;
int64_t float64_div(int64_t a, int64_t b) ;
int64_t estimateDiv128To64(uint64_t a0, int64_t a1, uint64_t b) ;
int32_t float64_le(uint64_t a, int64_t b) ;
int32_t float64_ge(int64_t a, int64_t b) ;
int64_t float64_neg(int64_t x) ;
int64_t local_sin(int64_t rad) ;
float64_t ullong_to_double(int64_t x) ;
unsigned int g2, g3, g1, g3;
